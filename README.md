# life-graft-death-predictive-analysis
Predictive modeling of liver patient outcomes using logistic regression and XGBoost to classify survival, transplantation, or death

üß¨ Pr√©diction du Pronostic Vital des Patients atteints de Maladies H√©patiques
üéØ Objectif du projet
L‚Äôobjectif de ce projet est de d√©velopper un mod√®le de classification multiclasses capable de pr√©dire le statut vital d‚Äôun patient atteint de maladie h√©patique. Le mod√®le doit estimer la probabilit√© que le patient appartienne √† l‚Äôune des trois classes suivantes :

Status_C : patient vivant

Status_CL : patient vivant ayant re√ßu une greffe

Status_D : patient d√©c√©d√©

L‚Äô√©valuation des performances repose sur la log loss, une m√©trique qui p√©nalise les probabilit√©s mal calibr√©es. L‚Äôobjectif est donc de minimiser cette valeur.

üì¶ Donn√©es
Le jeu de donn√©es est compos√© de 15 000 patients et 20 variables (dont 7 cat√©gorielles et 13 num√©riques), avec une colonne id pour l‚Äôidentification. Une particularit√© importante du jeu de donn√©es est la forte pr√©sence de valeurs manquantes, certaines variables ayant entre 42% et 55% de valeurs nulles.

üîç Analyse exploratoire
Une analyse initiale a mis en √©vidence :

De nombreuses valeurs manquantes n√©cessitant une strat√©gie adapt√©e

Une faible corr√©lation globale entre les variables num√©riques

Des distributions loin de la normalit√©, confirm√©es par des tests statistiques

Des tests de Kruskal-Wallis ont √©t√© utilis√©s pour comparer les distributions des variables num√©riques entre les classes. Ces tests ont r√©v√©l√© que plusieurs variables sont significativement diff√©rentes selon le statut du patient, ce qui confirme leur potentiel informatif pour la classification.

üßº Pr√©traitement des donn√©es
Imputation des valeurs manquantes selon le type de variable et sa corr√©lation avec d‚Äôautres.

Encodage des variables cat√©gorielles via One-Hot Encoding ou Label Encoding selon le mod√®le utilis√©.

D√©tection et traitement des valeurs aberrantes pour √©viter les biais dans la mod√©lisation.

üß† Mod√©lisation
Trois mod√®les principaux ont √©t√© test√©s :

1. R√©gression logistique multinomiale
Utilis√©e comme mod√®le de base

Donne des pr√©dictions probabilistes interpr√©tables

Score en validation crois√©e : log loss de 0,3286

Bonne calibration sans n√©cessit√© d‚Äôajustement

Moins performant sur le jeu de test Kaggle (d√©gradation du score)

2. XGBoost
Meilleure capacit√© √† g√©rer les non-lin√©arit√©s et les interactions

R√©sistant aux valeurs manquantes

Score public Kaggle am√©lior√© : log loss de 0,3479

3. R√©seau de neurones (MLP)
Exp√©riment√© en fin de projet

Mauvais r√©sultat sur Kaggle (log loss ‚âà 0,84)

Non adapt√© √† ce jeu de donn√©es (taille mod√©r√©e, bruit, peu de redondance)

‚úÖ Conclusion
Ce travail avait pour objectif de d√©velopper un mod√®le de classification capable de pr√©dire le statut clinique de patients atteints d‚Äôune maladie h√©patique, √† partir de donn√©es cliniques et biologiques. Apr√®s une phase d‚Äôanalyse exploratoire approfondie, nous avons trait√© les valeurs manquantes et les valeurs aberrantes afin d‚Äôassurer la qualit√© des donn√©es utilis√©es pour la mod√©lisation.

Nous avons d‚Äôabord construit un mod√®le de r√©gression logistique multinomiale, qui s‚Äôest r√©v√©l√© performant avec un log loss de 0,3286 lors de la validation crois√©e. L‚Äôanalyse de calibration a montr√© que ce mod√®le √©tait d√©j√† bien calibr√©, sans n√©cessiter d‚Äôajustements suppl√©mentaires. Cependant, lors de l‚Äô√©valuation sur le dataset externe de Kaggle, le score s‚Äôest d√©grad√©, r√©v√©lant des limites dans la g√©n√©ralisation.

Dans un souci d‚Äôam√©lioration, nous avons exp√©riment√© d‚Äôautres approches, notamment un mod√®le XGBoost, qui a permis de l√©g√®rement am√©liorer le score public sur Kaggle, atteignant 0,3479, confirmant une meilleure robustesse face aux sp√©cificit√©s du dataset externe. Enfin, l‚Äôutilisation d‚Äôun r√©seau de neurones (MLP) n‚Äôa pas √©t√© concluante, le score public ayant fortement chut√© √† 0,84, ce qui confirme que ce type de mod√®le n‚Äôest pas adapt√© au contexte et aux caract√©ristiques de nos donn√©es.

En conclusion, bien que plusieurs approches aient √©t√© test√©es, la r√©gression logistique multinomiale et XGBoost apparaissent comme les solutions les plus appropri√©es pour ce probl√®me multiclasses, avec des performances stables et interpr√©tables. Des pistes d‚Äôam√©lioration restent possibles, notamment en travaillant sur l‚Äô√©quilibre des classes, l‚Äôing√©nierie des variables ou encore des techniques avanc√©es de calibration pour affiner les probabilit√©s pr√©dites.
